{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680a0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  gender\n",
      "0  petronia       1\n",
      "1    bambie       1\n",
      "2      hali       1\n",
      "3      cain       0\n",
      "4     hanni       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "male_names = pd.read_csv('data/names/male.txt', header=None)[0].str.lower()\n",
    "female_names = pd.read_csv('data/names/female.txt', header=None)[0].str.lower()\n",
    "\n",
    "df_m = pd.DataFrame({'name': male_names, 'gender': 0})\n",
    "df_f = pd.DataFrame({'name': female_names, 'gender': 1})\n",
    "\n",
    "df = pd.concat([df_m, df_f]).sample(frac=1).reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "898453ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Vocabulary size: 34\n",
      "🔤 Example char2idx: {'<PAD>': 0, '<S>': 1, '<E>': 2, '<M>': 3, '<F>': 4, ' ': 5, \"'\": 6, '-': 7, 'a': 8, 'b': 9}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load names from the dataframe\n",
    "all_names = df['name'].tolist()\n",
    "\n",
    "# In your Step‑2 vocab build, include gender tokens:\n",
    "PAD = \"<PAD>\"\n",
    "START = \"<S>\"\n",
    "END = \"<E>\"\n",
    "GENDER_M = \"<M>\"\n",
    "GENDER_F = \"<F>\"\n",
    "\n",
    "# Build vocab from names as before, then prepend gender tokens:\n",
    "chars = sorted(set(\"\".join(all_names)))\n",
    "vocab = [PAD, START, END, GENDER_M, GENDER_F] + chars\n",
    "\n",
    "char2idx = {c: i for i, c in enumerate(vocab)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"🧠 Vocabulary size: {vocab_size}\")\n",
    "print(f\"🔤 Example char2idx: {dict(list(char2idx.items())[:10])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e20498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Input shape: (7944, 17)\n",
      "🎯 Target shape: (7944, 17)\n"
     ]
    }
   ],
   "source": [
    "def encode_name(name, gender_label):\n",
    "    \"\"\"\n",
    "    name: string, e.g. \"maria\"\n",
    "    gender_label: 0 (male) or 1 (female)\n",
    "    \"\"\"\n",
    "    gender_token = GENDER_M if gender_label == 0 else GENDER_F\n",
    "    seq = [gender_token, START] + list(name) + [END]\n",
    "    return [char2idx[c] for c in seq]\n",
    "\n",
    "# Re-prepare encoded_names & sequences:\n",
    "encoded = [encode_name(n, g) for n, g in zip(df['name'], df['gender'])]\n",
    "input_seqs = [seq[:-1] for seq in encoded]\n",
    "target_seqs = [seq[1:] for seq in encoded]\n",
    "\n",
    "# Pad them as before using char2idx[PAD]\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_len = max(len(seq) for seq in encoded)\n",
    "X = pad_sequences(input_seqs, maxlen=max_len-1, padding='post', \n",
    "                  value=char2idx[PAD])\n",
    "y = pad_sequences(target_seqs, maxlen=max_len-1, padding='post', \n",
    "                  value=char2idx[PAD])\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"✅ Input shape: {X.shape}\")\n",
    "print(f\"🎯 Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f46ab0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Input : <F><S>petronia\n",
      "   Target: <S>petronia<E>\n",
      "\n",
      "2. Input : <F><S>bambie\n",
      "   Target: <S>bambie<E>\n",
      "\n",
      "3. Input : <F><S>hali\n",
      "   Target: <S>hali<E>\n",
      "\n",
      "4. Input : <M><S>cain\n",
      "   Target: <S>cain<E>\n",
      "\n",
      "5. Input : <F><S>hanni\n",
      "   Target: <S>hanni<E>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to decode index sequence back to string\n",
    "def decode_sequence(seq):\n",
    "    return ''.join([idx2char.get(idx, '?') for idx in seq if idx != char2idx[PAD]])\n",
    "\n",
    "# Show a few sample input → output name training pairs\n",
    "for i in range(5):\n",
    "    input_seq = decode_sequence(X[i])\n",
    "    target_seq = decode_sequence(y[i])\n",
    "    print(f\"{i+1}. Input : {input_seq}\")\n",
    "    print(f\"   Target: {target_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f939a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed\n",
    "\n",
    "# Define model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(units=128, return_sequences=True),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e78221b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.5125 - loss: 2.1321 - val_accuracy: 0.6347 - val_loss: 1.3484 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6669 - loss: 1.2913 - val_accuracy: 0.6894 - val_loss: 1.0770 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6917 - loss: 1.0458 - val_accuracy: 0.6944 - val_loss: 0.9951 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6954 - loss: 0.9865 - val_accuracy: 0.6977 - val_loss: 0.9685 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7009 - loss: 0.9585 - val_accuracy: 0.7023 - val_loss: 0.9440 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7023 - loss: 0.9437 - val_accuracy: 0.7076 - val_loss: 0.9213 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7094 - loss: 0.9170 - val_accuracy: 0.7139 - val_loss: 0.9051 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7114 - loss: 0.9090 - val_accuracy: 0.7176 - val_loss: 0.8944 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7128 - loss: 0.8971 - val_accuracy: 0.7182 - val_loss: 0.8854 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7171 - loss: 0.8822 - val_accuracy: 0.7197 - val_loss: 0.8762 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7202 - loss: 0.8765 - val_accuracy: 0.7241 - val_loss: 0.8681 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7242 - loss: 0.8624 - val_accuracy: 0.7249 - val_loss: 0.8615 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7262 - loss: 0.8543 - val_accuracy: 0.7270 - val_loss: 0.8543 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7277 - loss: 0.8499 - val_accuracy: 0.7273 - val_loss: 0.8496 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7301 - loss: 0.8385 - val_accuracy: 0.7296 - val_loss: 0.8445 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7303 - loss: 0.8389 - val_accuracy: 0.7321 - val_loss: 0.8385 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7349 - loss: 0.8243 - val_accuracy: 0.7322 - val_loss: 0.8366 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7365 - loss: 0.8150 - val_accuracy: 0.7346 - val_loss: 0.8321 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7398 - loss: 0.8082 - val_accuracy: 0.7362 - val_loss: 0.8261 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7395 - loss: 0.8060 - val_accuracy: 0.7369 - val_loss: 0.8236 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7417 - loss: 0.7998 - val_accuracy: 0.7381 - val_loss: 0.8199 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7434 - loss: 0.7951 - val_accuracy: 0.7417 - val_loss: 0.8173 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7472 - loss: 0.7821 - val_accuracy: 0.7404 - val_loss: 0.8166 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7473 - loss: 0.7831 - val_accuracy: 0.7424 - val_loss: 0.8114 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7505 - loss: 0.7725 - val_accuracy: 0.7433 - val_loss: 0.8092 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7516 - loss: 0.7689 - val_accuracy: 0.7435 - val_loss: 0.8060 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7540 - loss: 0.7610 - val_accuracy: 0.7436 - val_loss: 0.8043 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7565 - loss: 0.7537 - val_accuracy: 0.7414 - val_loss: 0.8047 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7571 - loss: 0.7498 - val_accuracy: 0.7459 - val_loss: 0.8008 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7579 - loss: 0.7470 - val_accuracy: 0.7469 - val_loss: 0.7979 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x277f8bbafe0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add callbacks to save time\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    X, y,\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18a9a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sampling helper (unchanged)\n",
    "def sample_from_probs(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds + 1e-10) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(preds), p=preds)\n",
    "\n",
    "# Corrected generate_name\n",
    "def generate_name(model, char2idx, idx2char,\n",
    "                  gender_label, temperature=1.0, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = X.shape[1]\n",
    "\n",
    "    # Start sequence with gender token + START\n",
    "    gender_token = GENDER_M if gender_label == 0 else GENDER_F\n",
    "    input_seq = [char2idx[gender_token], char2idx[START]]\n",
    "    name = ''\n",
    "\n",
    "    for _ in range(max_len-2):  # we've already got 2 tokens\n",
    "        padded = pad_sequences([input_seq],\n",
    "                               maxlen=max_len,\n",
    "                               padding='post',\n",
    "                               value=char2idx[PAD])\n",
    "        preds = model.predict(padded, verbose=0)[0, len(input_seq)-1]\n",
    "        next_idx = sample_from_probs(preds, temperature)\n",
    "        next_char = idx2char[next_idx]\n",
    "\n",
    "        if next_char == END:\n",
    "            break\n",
    "        name += next_char\n",
    "        input_seq.append(next_idx)\n",
    "\n",
    "    return name.capitalize()\n",
    "\n",
    "def generate_names(model, char2idx, idx2char, gender_label, n=10, temperature=1.0):\n",
    "    return [generate_name(model, char2idx, idx2char, gender_label, temperature)\n",
    "            for _ in range(n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e049c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male: ['Riddy', 'Tabrey', 'Gordon', 'Lean', 'Abnaviah']\n",
      "Female: ['Sandre', 'Bettee', 'Kaila', 'Andrise', 'Susa']\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 male names\n",
    "male_samples = generate_names(model, char2idx, idx2char, gender_label=0, n=5, temperature=0.8)\n",
    "print(\"Male:\", male_samples)\n",
    "\n",
    "# Generate 5 female names\n",
    "female_samples = generate_names(model, char2idx, idx2char, gender_label=1, n=5, temperature=0.8)\n",
    "print(\"Female:\", female_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46d3d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 📦 Save the trained model\n",
    "model.save(\"models/namegen_lstm.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ceb1b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"models/char_mappings.pkl\", \"wb\") as f:\n",
    "    pickle.dump({'char2idx': char2idx, 'idx2char': idx2char}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d5c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
